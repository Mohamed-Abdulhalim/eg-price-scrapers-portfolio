from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import time
import supabase
from supabase import create_client
import chromedriver_autoinstaller
import os, sys

chromedriver_autoinstaller.install()
ACCESSORY_KEYWORDS_AR = [
    "Ø¬Ø±Ø§Ø¨", "ÙƒÙØ±", "Ø­Ù…Ø§ÙŠØ©", "ØºØ·Ø§Ø¡", "Ù„Ø§ØµÙ‚Ø©", "Ø´Ø§Ø´Ø©", "ÙˆØ§Ù‚ÙŠ",
    "Ø³Ù…Ø§Ø¹Ø©", "Ø³Ù…Ø§Ø¹Ø§Øª", "Ù‚Ù„Ù…", "Ø¹Ø¯Ø³Ø©", "Ø­Ø§ÙØ¸Ø©", "ØºØ·Ù‰", "ÙƒØ§Ù…ÙŠØ±Ø§",
    "ÙƒØ§Ø±Ù„"
]

ACCESSORY_KEYWORDS_EN = [
    "case", "cover", "screen", "protector", "glass", "accessory", "charger",
    "cable", "headset", "silicone", "bumper", "shell", "skin", "sleeve", "lens", "wallet"
]

# Supabase config

SUPABASE_URL = os.environ["SUPABASE_URL"]
SUPABASE_KEY = os.environ["SUPABASE_SERVICE_ROLE_KEY"] # use service_role for writes
if not SUPABASE_URL or not SUPABASE_KEY:
    sys.exit("Missing SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY (set as Actions secrets and mapped in scrape.yml).")
supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)

def is_accessory(title):
    title_lower = title.lower()
    for word in ACCESSORY_KEYWORDS_AR:
        if word in title_lower:
            return True
    for word in ACCESSORY_KEYWORDS_EN:
        if word in title_lower:
            return True
    return False

def extract_price(product_card):
    special = product_card.select_one(".special-price .price")
    if special:
        return special.text

    regular = product_card.select_one(".price")
    if regular:
        return regular.text

    return None

def search_2b(product_name, category=""):
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920x1080")
    driver = webdriver.Chrome(options=options)

    print(f"[ğŸ”] Searching 2B for: {product_name}")
    
    base_url = f"https://2b.com.eg/ar/catalogsearch/result/?q={product_name}"
    driver.get(base_url)
    time.sleep(2)

    soup = BeautifulSoup(driver.page_source, "html.parser")
    product_cards = soup.find_all("li", class_="item product product-item")
    all_products = []
    seen_titles = set()

    for card in product_cards:
        title_tag = card.find("a", class_="product-item-link")
        if not title_tag:
            continue
        title = title_tag.text.strip()

        if category.lower() == "mobiles" and is_accessory(title):
            continue
        if title in seen_titles:
            continue
        seen_titles.add(title)

        price_str = extract_price(card)
        if not price_str:
            continue

        price_str = price_str.replace("Ø¬.Ù….â€", "").replace(",", "").replace("Ù¬", "").replace("\u00a0", "").strip()
        try:
            price = float(price_str)
        except:
            price = 0.0

        product_data = {
            "store": "2B",
            "title": title,
            "price": price,
            "category": "mobiles" if category.lower() == "mobiles" else "other",
            "query": product_name
        }
        all_products.append(product_data)

        # Push to Supabase
        try:
            supabase_client.table("products").upsert(product_data).execute()
        except Exception as e:
            print(f"âŒ Failed to upload product: {e}")

    driver.quit()

    print(f"\nâœ… Found {len(all_products)} products on 2B for '{product_name}':")
    print("-" * 80)
    for i, product in enumerate(all_products, 1):
        print(f"{i}. Ø§Ù„Ø³Ø¹Ø±: {product['price']} Ø¬Ù†ÙŠÙ‡")
        print(f"   Ø§Ù„Ø§Ø³Ù…: {product['title']}")
        print("-" * 80)

    return all_products

if __name__ == "__main__":
    product = input("ğŸ” Ø§ÙƒØªØ¨ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬ Ù„Ù„Ø¨Ø­Ø«: ").strip()
    category = input("ğŸ“‚ Ø§ÙƒØªØ¨ Ø§Ù„ÙØ¦Ø© (Ø§ÙƒØªØ¨ 'mobiles' Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¥ÙƒØ³Ø³ÙˆØ§Ø±Ø§Øª): ").strip()
    search_2b(product, category)
